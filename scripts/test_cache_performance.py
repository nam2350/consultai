#!/usr/bin/env python3
"""
ìºì‹± ì‹œìŠ¤í…œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ë™ì¼í•œ ìš”ì²­ì„ ì—¬ëŸ¬ ë²ˆ ë³´ë‚´ì„œ ìºì‹œ ì„±ëŠ¥ í–¥ìƒì„ ì¸¡ì •í•©ë‹ˆë‹¤.
"""

import asyncio
import time
import json
import statistics
from pathlib import Path
import httpx

class CachePerformanceTester:
    def __init__(self, base_url="http://localhost:8000"):
        self.base_url = base_url
        self.client = httpx.AsyncClient(timeout=120.0)
    
    async def load_test_data(self):
        """í…ŒìŠ¤íŠ¸ìš© ì‹¤ì œ í†µí™” ë°ì´í„° ë¡œë“œ"""
        try:
            # call_dataì—ì„œ ì‹¤ì œ íŒŒì¼ í•˜ë‚˜ ì„ íƒ
            call_data_dir = Path("call_data/2025-07-15")
            json_files = list(call_data_dir.glob("*.json"))
            
            if not json_files:
                raise FileNotFoundError("í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            # ì²« ë²ˆì§¸ íŒŒì¼ ì‚¬ìš©
            test_file = json_files[0]
            with open(test_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            conversation_text = data.get('conversation_text', '')
            if not conversation_text:
                raise ValueError("conversation_textê°€ ì—†ìŠµë‹ˆë‹¤")
            
            print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {test_file.name}")
            print(f"í…ìŠ¤íŠ¸ ê¸¸ì´: {len(conversation_text)} ë¬¸ì")
            
            return {
                "consultation_id": f"cache_test_{int(time.time())}",
                "consultation_content": conversation_text,
                "stt_data": {
                    "conversation_text": conversation_text
                },
                "ai_tier": "llm",
                "llm_model": "qwen3_4b",
                "options": {
                    "include_summary": True,
                    "include_category_recommendation": True,
                    "include_title_generation": True,
                    "max_summary_length": 300
                }
            }
            
        except Exception as e:
            print(f"ERROR: í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    async def single_analysis_request(self, request_data):
        """ë‹¨ì¼ ë¶„ì„ ìš”ì²­ ì‹¤í–‰"""
        start_time = time.time()
        
        try:
            response = await self.client.post(
                f"{self.base_url}/api/v1/consultation/analyze",
                json=request_data
            )
            
            end_time = time.time()
            duration = end_time - start_time
            
            if response.status_code == 200:
                result = response.json()
                processing_time = result.get('metadata', {}).get('processing_time', 0)
                model_used = result.get('metadata', {}).get('model_used', 'Unknown')
                cache_used = "(ìºì‹œ)" in model_used
                
                return {
                    "success": True,
                    "total_time": duration,
                    "processing_time": processing_time,
                    "model_used": model_used,
                    "cache_used": cache_used,
                    "categories_count": len(result.get('results', {}).get('recommended_categories', [])),
                    "titles_count": len(result.get('results', {}).get('generated_titles', []))
                }
            else:
                return {
                    "success": False,
                    "error": f"HTTP {response.status_code}",
                    "total_time": duration
                }
                
        except Exception as e:
            end_time = time.time()
            return {
                "success": False,
                "error": str(e),
                "total_time": end_time - start_time
            }
    
    async def run_cache_performance_test(self, iterations=5):
        """ìºì‹œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("ìºì‹œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
        print("=" * 50)
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
        test_data = await self.load_test_data()
        if not test_data:
            return
        
        results = []
        
        for i in range(iterations):
            print(f"\n[{i+1}/{iterations}] ë¶„ì„ ìš”ì²­ ì‹¤í–‰...")
            
            result = await self.single_analysis_request(test_data)
            results.append(result)
            
            if result["success"]:
                cache_status = "CACHE HIT" if result["cache_used"] else "CACHE MISS"
                print(f"  ìƒíƒœ: SUCCESS ({cache_status})")
                print(f"  ì´ ì‹œê°„: {result['total_time']:.2f}ì´ˆ")
                print(f"  ì²˜ë¦¬ ì‹œê°„: {result['processing_time']:.2f}ì´ˆ")
                print(f"  ëª¨ë¸: {result['model_used']}")
                print(f"  ì¹´í…Œê³ ë¦¬: {result['categories_count']}ê°œ")
                print(f"  ì œëª©: {result['titles_count']}ê°œ")
            else:
                print(f"  ìƒíƒœ: FAILED - {result['error']}")
                print(f"  ì†Œìš” ì‹œê°„: {result['total_time']:.2f}ì´ˆ")
        
        # ê²°ê³¼ ë¶„ì„
        await self.analyze_results(results)
    
    async def analyze_results(self, results):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„"""
        print("\n" + "=" * 50)
        print("ğŸ“Š ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„")
        print("=" * 50)
        
        successful_results = [r for r in results if r["success"]]
        if not successful_results:
            print("âŒ ì„±ê³µí•œ ìš”ì²­ì´ ì—†ìŠµë‹ˆë‹¤!")
            return
        
        # ìºì‹œ íˆíŠ¸/ë¯¸ìŠ¤ ë¶„ë¦¬
        cache_hits = [r for r in successful_results if r["cache_used"]]
        cache_misses = [r for r in successful_results if not r["cache_used"]]
        
        print(f"ì´ ìš”ì²­: {len(results)}ê°œ")
        print(f"ì„±ê³µ: {len(successful_results)}ê°œ")
        print(f"ìºì‹œ íˆíŠ¸: {len(cache_hits)}ê°œ")
        print(f"ìºì‹œ ë¯¸ìŠ¤: {len(cache_misses)}ê°œ")
        
        if cache_misses:
            miss_times = [r["total_time"] for r in cache_misses]
            print(f"\nğŸ”¥ ìºì‹œ ë¯¸ìŠ¤ (AI ë¶„ì„):")
            print(f"  í‰ê·  ì‹œê°„: {statistics.mean(miss_times):.2f}ì´ˆ")
            print(f"  ìµœì†Œ/ìµœëŒ€: {min(miss_times):.2f}ì´ˆ / {max(miss_times):.2f}ì´ˆ")
        
        if cache_hits:
            hit_times = [r["total_time"] for r in cache_hits]
            print(f"\nâš¡ ìºì‹œ íˆíŠ¸ (ì¦‰ì‹œ ë°˜í™˜):")
            print(f"  í‰ê·  ì‹œê°„: {statistics.mean(hit_times):.2f}ì´ˆ")
            print(f"  ìµœì†Œ/ìµœëŒ€: {min(hit_times):.2f}ì´ˆ / {max(hit_times):.2f}ì´ˆ")
            
            if cache_misses:
                improvement = ((statistics.mean(miss_times) - statistics.mean(hit_times)) / statistics.mean(miss_times)) * 100
                speed_ratio = statistics.mean(miss_times) / statistics.mean(hit_times)
                print(f"\nğŸš€ ì„±ëŠ¥ í–¥ìƒ:")
                print(f"  ê°œì„ ë¥ : {improvement:.1f}% í–¥ìƒ")
                print(f"  ì†ë„ë¹„: {speed_ratio:.1f}ë°° ë¹¨ë¼ì§")
        
        # í’ˆì§ˆ ì¼ê´€ì„± í™•ì¸
        if len(successful_results) > 1:
            categories_counts = [r["categories_count"] for r in successful_results]
            titles_counts = [r["titles_count"] for r in successful_results]
            
            categories_consistent = len(set(categories_counts)) == 1
            titles_consistent = len(set(titles_counts)) == 1
            
            print(f"\nâœ… í’ˆì§ˆ ì¼ê´€ì„±:")
            print(f"  ì¹´í…Œê³ ë¦¬ ê°œìˆ˜ ì¼ì¹˜: {'YES' if categories_consistent else 'NO'}")
            print(f"  ì œëª© ê°œìˆ˜ ì¼ì¹˜: {'YES' if titles_consistent else 'NO'}")
    
    async def close(self):
        """í´ë¼ì´ì–¸íŠ¸ ì¢…ë£Œ"""
        await self.client.aclose()

async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    tester = CachePerformanceTester()
    
    try:
        await tester.run_cache_performance_test(iterations=3)
    finally:
        await tester.close()

if __name__ == "__main__":
    print("ğŸ§ª ìºì‹± ì‹œìŠ¤í…œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
    print("ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”: python -m uvicorn main:app --reload")
    print()
    
    asyncio.run(main())
